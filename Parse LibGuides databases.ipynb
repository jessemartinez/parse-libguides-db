{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import pprint\n",
    "import csv\n",
    "import time\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex objects\n",
    "proxy_re = re.compile('proxy\\.bc\\.edu\\/login\\?url=', re.IGNORECASE)\n",
    "remove_protocol_re = re.compile('https?:\\/\\/', re.IGNORECASE)\n",
    "domain_name_re = re.compile('(www\\.)?(?P<dn>[a-zA-Z0-9.\\-_]*).*', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0   1     2            3    4\n",
    "# ID, Name, Description, URL, Created,\n",
    "#\n",
    "# 5       6      7                      8          9 \n",
    "# Vendor, Types, Alt. Names / Keywords, Use Proxy, Friendly URL,\n",
    "#\n",
    "# 10        11         12                13   14\n",
    "# Subjects, More Info, Librarian Review, New, Trial, \n",
    "#\n",
    "# 15       16              17      18             19\n",
    "# Popular, Permitted Uses, Hidden, Internal Note, Owner\n",
    "\n",
    "db_url_raw = []\n",
    "db_url_dn_raw = []\n",
    "with open('az_database_list.csv', newline='') as csvfile:\n",
    "    db_reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    # skip the header\n",
    "    next(db_reader, None)  # skip the headers\n",
    "    \n",
    "    for row in db_reader:\n",
    "        db_name = row[1]\n",
    "        db_url = row[3]\n",
    "        db_uses_proxy = row[8]\n",
    "        \n",
    "        db_url_lower = db_url.lower()\n",
    "        \n",
    "        # check if db uses proxy -- ignore if db_uses_proxy == \"No\"\n",
    "        if db_uses_proxy == \"Yes\":\n",
    "            # remove url protocol\n",
    "            db_url_clean = re.sub(remove_protocol_re, \"\", db_url_lower)\n",
    "\n",
    "            # strip out trailing forward slash\n",
    "            db_url_clean = db_url_clean.rstrip('/')\n",
    "            \n",
    "            # db_dict = {\n",
    "            #     'name': db_name,\n",
    "            #     'url': db_url_clean\n",
    "            # }\n",
    "            # db_url_raw.append(db_dict)\n",
    "    \n",
    "            db_url_raw.append(db_url_clean)\n",
    "\n",
    "            # for db_url_dn_raw, ignore any urls that contain 'bc.edu' and 'wrds-web.wharton.upenn.edu'\n",
    "            if \"bc.edu\" not in db_url_lower and \"wrds-web.wharton.upenn.edu\" not in db_url_lower:\n",
    "                db_url_dn_raw.append(db_url_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_url_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_url_dn_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_url_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# db_url_dn_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove dupes from db_url_raw\n",
    "db_url_no_dupes = list(set(db_url_raw))\n",
    "len(db_url_no_dupes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort db_url_no_dupes\n",
    "db_url_no_dupes.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_url_no_dupes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_url_no_dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out to json\n",
    "db_list = {\n",
    "    \"databases\": db_url_no_dupes,\n",
    "    \"date_stamp\": time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "}\n",
    "with open('all_databases.txt', 'w') as outfile:\n",
    "    json.dump(db_list, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out to javascript\n",
    "with open('all_databases.js', 'w') as outfile:\n",
    "    outfile.write(\"var db_full_names = [\\n\")\n",
    "    for item in db_url_no_dupes:\n",
    "      outfile.write(\"\\t'%s',\\n\" % item)\n",
    "    outfile.write(\"];\\n\")\n",
    "    outfile.write(\"var db_full_names_date_stamp = '{}';\\n\".format(time.strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse out the domain name for every url in db_url_dn_raw\n",
    "db_url_dn = []\n",
    "for url in db_url_dn_raw:\n",
    "    get_dn = domain_name_re.search(url)\n",
    "    if get_dn:\n",
    "        matched_dn = get_dn.group(\"dn\")\n",
    "        if matched_dn:\n",
    "            db_url_dn.append(matched_dn)\n",
    "        else:\n",
    "            # TODO log an error here\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove dupes from db_url_dn_raw\n",
    "db_url_dn_no_dupes = list(set(db_url_dn))\n",
    "len(db_url_dn_no_dupes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort list\n",
    "db_url_dn_no_dupes.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_url_dn_no_dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out to json\n",
    "db_list = {\n",
    "    \"databases\": db_url_dn_no_dupes,\n",
    "    \"date_stamp\": time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "}\n",
    "with open('all_databases_domain_names.txt', 'w') as outfile:\n",
    "    json.dump(db_list, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out to javascript\n",
    "with open('all_databases_domain_names.js', 'w') as outfile:\n",
    "    outfile.write(\"var db_unique_domain_names = [\\n\")\n",
    "    for item in db_url_dn_no_dupes:\n",
    "      outfile.write(\"\\t'%s',\\n\" % item)\n",
    "    outfile.write(\"];\\n\")\n",
    "    outfile.write(\"var db_unique_domain_names_date_stamp = '{}';\\n\".format(time.strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
